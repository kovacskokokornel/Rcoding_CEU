---
title: "Assignment 12"
author: "Kornel Kovacs"
date: '2019 12 06 '
output:
  html_document: default
  pdf_document: default
---

## General setup for the whole project

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pbapply)
library(plotrix)
```

```{r, message = FALSE }
df <- read_csv("./hotels-vienna.csv")
```

## Exercise 1

I check the mean of the price in the data.
```{r}
mean(df$price)
```

I am simulating 1 000 samples with replacement and saving their means in a df.
```{r, warning = FALSE}
bootstrap_df <- data_frame(num = 1:1000) %>% 
    group_by(num) %>% 
    mutate(means = mean(sample(df$price, replace = TRUE)))
```

Therefore, the bootstrap standard deviation of this mean (aka ‘the standard error’) can be calculated with ease.

```{r}
sd(bootstrap_df$means)
```

## Exercise 2

I designed the function as the exercise wished.

```{r}
bootstrap_mean <- function(B,v) {
  bootstrap_df <- data_frame(num = 1:B) %>% 
    group_by(num) %>% 
    mutate(means = mean(sample(v, replace = TRUE)))
  return(sd(bootstrap_df$means))
}
```

I apply the function on a bunch of values for the plots.

```{r}
simulated_deviations <- unlist(pblapply(2:1000, bootstrap_mean, v=df$price))
df_to_plot <- data.frame(number_of_simulations = 2:1000, 
                         standard_dev = simulated_deviations)
```

This is the first way of visualisation. It shows standard deviations as a function of how many values we simulate. We can see a nice funnel-like pattern.

```{r}
ggplot(df_to_plot, aes(x = number_of_simulations, y = standard_dev)) + 
  geom_point() +
  xlab("Number of simulations") +
  ylab("Standard deviation of mean")
```

A histogram of the standard deviations gives you a hint about the distribution of values. It seems to be normally distributed.


```{r}
ggplot(df_to_plot, aes(x=standard_dev)) + 
  geom_histogram(bins = 100) +
  ylab("Number of occurrences") +
  xlab("Standard deviation of mean")
```


## Exercise 3

I found a nice package called ``plotrix`` which has a function that calculates the standard error for mean ``price``.

```{r}
std.error(df$price)
```

If you are conservative and do not like to use new packages, you may also compute the same result manually.

```{r}
(conservative_std_error <- sd(df$price)/sqrt(length(df$price)))
```


## Exercise 4

I define the function to calculate standard deviation for median values.

```{r}
bootstrap_median <- function(B,v) {
  bootstrap_df <- data_frame(num = 1:B) %>% 
    group_by(num) %>% 
    mutate(medians = median(sample(v, replace = TRUE)))
  return(sd(bootstrap_df$medians))
}
```

I also try it out.

```{r}
bootstrap_median(1000, df$price)
```

## Exercise 5

I defined my Swiss army knife, a multifunctional method. I had to differentiate between DFs and vectors because their sampling functions are named slightly different.

```{r}
bootstrap_func <- function(B,v, method) {
  if (is.data.frame(v)) {
    bootstrap_df <- data_frame(num = 1:B) %>% 
    group_by(num) %>% 
    mutate(metric_value = method(sample_n(v, nrow(v), replace = TRUE)))
    return(sd(bootstrap_df$metric_value))
  } else {
    bootstrap_df <- data_frame(num = 1:B) %>% 
    group_by(num) %>% 
    mutate(metric_value = method(sample(v, replace = TRUE)))
    return(sd(bootstrap_df$metric_value))
  }
}
```

Example calls:

```{r}
bootstrap_func(1000, df$price, sd)
```

```{r}
bootstrap_func(1000, df$price, max)
```

```{r}
bootstrap_func(1000, df$price, mean)
```

```{r}
bootstrap_func(1000, df$price, median)
```

As we do not have a basic function for the top quartile, some hacking is needed for this case.

```{r}
bootstrap_func(1000, df$price,function(metric) quantile(metric)[4])
```

## Exercise 6

I define the function that returns the adequat value of the regression.

```{r}
get_coeff <- function(data){
  mod <- lm(price ~ distance_alter, data = data)
  return(summary(mod)$coefficients[2, 1])
}
```

I use the above as an input for the general function. This should return the standard error.

```{r}
bootstrap_func(1000, df, get_coeff)
```

## Exercise 7

I have the model summary here. I do not see a great difference in the standard error of the coefficient compared to the bootstrap standard error. However, I have no intention to deny that there is. It may vary by simply random sampling, sample sizes could also matter. If you knit my Rmd file, then it is very likely that you will have different results compared to the ones in the submitted HTML and PDF files.

```{r}
mod <- lm(price ~ distance_alter, data = df)
summary(mod)
```
